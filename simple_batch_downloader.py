#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€åŒ–ç‰ˆæ‰¹é‡YouTubeè¯„è®ºä¸‹è½½å·¥å…·
ä¸ä¾èµ–seleniumï¼Œé€šè¿‡æ‰‹åŠ¨è¾“å…¥URLåˆ—è¡¨æˆ–ä»æ–‡ä»¶è¯»å–è¿›è¡Œæ‰¹é‡ä¸‹è½½
"""

import os
import sys
import time
import json
import csv
import subprocess
from datetime import datetime


class SimpleBatchDownloader:
    def __init__(self, output_dir="simple_batch_output"):
        """
        åˆå§‹åŒ–ç®€åŒ–ç‰ˆæ‰¹é‡ä¸‹è½½å™¨
        
        Args:
            output_dir (str): è¾“å‡ºç›®å½•
        """
        self.output_dir = output_dir
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
            
        # åˆ›å»ºå­ç›®å½•
        self.comments_dir = os.path.join(output_dir, "comments")
        self.logs_dir = os.path.join(output_dir, "logs")
        
        for dir_path in [self.comments_dir, self.logs_dir]:
            if not os.path.exists(dir_path):
                os.makedirs(dir_path)
            
        print(f"ğŸš€ ç®€åŒ–ç‰ˆæ‰¹é‡è¯„è®ºä¸‹è½½å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        print(f"  ğŸ“‚ è¯„è®ºç›®å½•: {self.comments_dir}")
        print(f"  ğŸ“‚ æ—¥å¿—ç›®å½•: {self.logs_dir}")

    def extract_video_id(self, url):
        """ä»YouTube URLä¸­æå–è§†é¢‘ID"""
        try:
            if "watch?v=" in url:
                return url.split("watch?v=")[1].split("&")[0]
            elif "/shorts/" in url:
                return url.split("/shorts/")[1].split("?")[0]
            elif "youtu.be/" in url:
                return url.split("youtu.be/")[1].split("?")[0]
            else:
                return "unknown"
        except:
            return "unknown"

    def extract_video_info_from_url(self, url, index=1):
        """ä»URLæå–åŸºæœ¬è§†é¢‘ä¿¡æ¯"""
        video_id = self.extract_video_id(url)
        video_type = "shorts" if "/shorts/" in url else "watch"
        
        return {
            "åºå·": index,
            "æ ‡é¢˜": f"Video_{video_id}",
            "URL": url,
            "è§†é¢‘ID": video_id,
            "ç±»å‹": video_type,
            "å…³é”®è¯": "æ‰‹åŠ¨è¾“å…¥",
            "è·å–æ—¶é—´": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }

    def download_comments_for_video(self, video_info, limit=100, sort=1, language=None, pretty=True):
        """
        ä¸ºå•ä¸ªè§†é¢‘ä¸‹è½½è¯„è®º
        
        Args:
            video_info (dict): è§†é¢‘ä¿¡æ¯
            limit (int): è¯„è®ºæ•°é‡é™åˆ¶
            sort (int): æ’åºæ–¹å¼ (0=çƒ­é—¨, 1=æœ€æ–°)
            language (str): è¯­è¨€è®¾ç½®
            pretty (bool): æ˜¯å¦æ ¼å¼åŒ–JSON
            
        Returns:
            tuple: (æ˜¯å¦æˆåŠŸ, è¾“å‡ºæ–‡ä»¶è·¯å¾„)
        """
        video_id = video_info.get('è§†é¢‘ID', 'unknown')
        video_title = video_info.get('æ ‡é¢˜', 'unknown')
        
        if video_id == 'unknown':
            print(f"âŒ æ— æ•ˆçš„è§†é¢‘ID: {video_title}")
            return False, None
            
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        safe_title = "".join(c for c in video_title if c.isalnum() or c in (' ', '-', '_')).strip()[:50]
        output_filename = f"{video_id}_{safe_title}.json"
        output_path = os.path.join(self.comments_dir, output_filename)
        
        # æ„å»ºå‘½ä»¤
        cmd = [
            sys.executable, "-m", "youtube_comment_downloader",
            "--youtubeid", video_id,
            "--output", output_path,
            "--limit", str(limit),
            "--sort", str(sort)
        ]
        
        if language:
            cmd.extend(["--language", language])
            
        if pretty:
            cmd.append("--pretty")
        
        try:
            print(f"â¬‡ï¸ æ­£åœ¨ä¸‹è½½è¯„è®º: {video_title[:50]}...")
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
            
            if result.returncode == 0:
                print(f"âœ… è¯„è®ºä¸‹è½½æˆåŠŸ: {output_filename}")
                return True, output_path
            else:
                print(f"âŒ è¯„è®ºä¸‹è½½å¤±è´¥: {video_title}")
                print(f"é”™è¯¯ä¿¡æ¯: {result.stderr}")
                return False, None
                
        except subprocess.TimeoutExpired:
            print(f"â° ä¸‹è½½è¶…æ—¶: {video_title}")
            return False, None
        except Exception as e:
            print(f"âŒ ä¸‹è½½å‡ºé”™: {e}")
            return False, None

    def batch_download_comments(self, video_list, limit=100, sort=1, language=None, pretty=True, delay=2):
        """
        æ‰¹é‡ä¸‹è½½è¯„è®º
        
        Args:
            video_list (list): è§†é¢‘ä¿¡æ¯åˆ—è¡¨
            limit (int): æ¯ä¸ªè§†é¢‘çš„è¯„è®ºæ•°é‡é™åˆ¶
            sort (int): æ’åºæ–¹å¼
            language (str): è¯­è¨€è®¾ç½®
            pretty (bool): æ˜¯å¦æ ¼å¼åŒ–JSON
            delay (int): ä¸‹è½½é—´éš”ç§’æ•°
            
        Returns:
            dict: ä¸‹è½½ç»“æœç»Ÿè®¡
        """
        print(f"\nğŸš€ å¼€å§‹æ‰¹é‡ä¸‹è½½ {len(video_list)} ä¸ªè§†é¢‘çš„è¯„è®º")
        
        success_count = 0
        failed_count = 0
        failed_videos = []
        
        # åˆ›å»ºä¸‹è½½æ—¥å¿—
        log_file = os.path.join(self.logs_dir, f"download_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt")
        
        with open(log_file, 'w', encoding='utf-8') as log:
            log.write(f"æ‰¹é‡ä¸‹è½½å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            log.write(f"æ€»è§†é¢‘æ•°: {len(video_list)}\n")
            log.write(f"å‚æ•°è®¾ç½®: limit={limit}, sort={sort}, language={language}, pretty={pretty}\n")
            log.write("="*80 + "\n\n")
            
            for i, video_info in enumerate(video_list, 1):
                print(f"\n{'='*60}")
                print(f"æ­£åœ¨å¤„ç†ç¬¬ {i}/{len(video_list)} ä¸ªè§†é¢‘")
                
                start_time = time.time()
                success, output_path = self.download_comments_for_video(
                    video_info, limit, sort, language, pretty
                )
                end_time = time.time()
                
                # è®°å½•æ—¥å¿—
                log_entry = f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] "
                log_entry += f"è§†é¢‘ {i}/{len(video_list)}: {video_info.get('æ ‡é¢˜', 'unknown')[:50]}\n"
                log_entry += f"è§†é¢‘ID: {video_info.get('è§†é¢‘ID', 'unknown')}\n"
                log_entry += f"URL: {video_info.get('URL', 'unknown')}\n"
                
                if success:
                    success_count += 1
                    log_entry += f"çŠ¶æ€: âœ… æˆåŠŸ\n"
                    log_entry += f"è¾“å‡ºæ–‡ä»¶: {output_path}\n"
                else:
                    failed_count += 1
                    failed_videos.append(video_info)
                    log_entry += f"çŠ¶æ€: âŒ å¤±è´¥\n"
                
                log_entry += f"è€—æ—¶: {end_time - start_time:.2f}ç§’\n"
                log_entry += "-" * 80 + "\n\n"
                
                log.write(log_entry)
                log.flush()
                
                # æ·»åŠ å»¶è¿Ÿ
                if i < len(video_list) and delay > 0:
                    print(f"â±ï¸ ç­‰å¾… {delay} ç§’åç»§ç»­...")
                    time.sleep(delay)
            
            # å†™å…¥æœ€ç»ˆç»Ÿè®¡
            log.write(f"\næ‰¹é‡ä¸‹è½½å®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            log.write(f"æˆåŠŸä¸‹è½½: {success_count} ä¸ª\n")
            log.write(f"ä¸‹è½½å¤±è´¥: {failed_count} ä¸ª\n")
            log.write(f"æˆåŠŸç‡: {success_count/len(video_list)*100:.1f}%\n")
        
        result = {
            "æ€»æ•°": len(video_list),
            "æˆåŠŸ": success_count,
            "å¤±è´¥": failed_count,
            "æˆåŠŸç‡": f"{success_count/len(video_list)*100:.1f}%",
            "å¤±è´¥è§†é¢‘": failed_videos,
            "æ—¥å¿—æ–‡ä»¶": log_file
        }
        
        print(f"\nğŸŠ æ‰¹é‡ä¸‹è½½å®Œæˆ!")
        print(f"ğŸ“Š æˆåŠŸ: {success_count}, å¤±è´¥: {failed_count}, æˆåŠŸç‡: {result['æˆåŠŸç‡']}")
        print(f"ğŸ“‹ è¯¦ç»†æ—¥å¿—: {log_file}")
        
        return result

    def save_video_list_to_file(self, video_list, filename=None):
        """ä¿å­˜è§†é¢‘åˆ—è¡¨åˆ°æ–‡ä»¶"""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"video_list_{timestamp}.json"
            
        filepath = os.path.join(self.output_dir, filename)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(video_list, f, ensure_ascii=False, indent=2)
            
        print(f"ğŸ’¾ è§†é¢‘åˆ—è¡¨å·²ä¿å­˜: {filepath}")
        return filepath

    def load_video_list_from_file(self, filepath):
        """ä»æ–‡ä»¶åŠ è½½è§†é¢‘åˆ—è¡¨"""
        if not os.path.exists(filepath):
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {filepath}")
            
        video_list = []
        
        if filepath.endswith('.json'):
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)
                if isinstance(data, list):
                    video_list = data
                elif isinstance(data, dict) and 'videos' in data:
                    video_list = data['videos']
                else:
                    raise ValueError("JSONæ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®")
                    
        elif filepath.endswith('.csv'):
            import pandas as pd
            df = pd.read_csv(filepath)
            video_list = df.to_dict('records')
            
        elif filepath.endswith('.txt'):
            with open(filepath, 'r', encoding='utf-8') as f:
                urls = [line.strip() for line in f if line.strip() and not line.startswith('#')]
                for i, url in enumerate(urls):
                    video_list.append(self.extract_video_info_from_url(url, i + 1))
        else:
            raise ValueError("ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œè¯·ä½¿ç”¨ .json, .csv æˆ– .txt æ–‡ä»¶")
            
        return video_list

    def generate_report(self, download_results):
        """ç”Ÿæˆä¸‹è½½æŠ¥å‘Š"""
        print(f"\n{'='*60}")
        print("ğŸ“Š æ‰¹é‡ä¸‹è½½ç»“æœæŠ¥å‘Š")
        print(f"{'='*60}")
        
        print("â¬‡ï¸ è¯„è®ºä¸‹è½½ç»“æœ:")
        print(f"   ğŸ“Š æ€»è§†é¢‘æ•°: {download_results['æ€»æ•°']}")
        print(f"   âœ… æˆåŠŸä¸‹è½½: {download_results['æˆåŠŸ']}")
        print(f"   âŒ ä¸‹è½½å¤±è´¥: {download_results['å¤±è´¥']}")
        print(f"   ğŸ“ˆ æˆåŠŸç‡: {download_results['æˆåŠŸç‡']}")
        print(f"   ğŸ“‹ æ—¥å¿—æ–‡ä»¶: {download_results['æ—¥å¿—æ–‡ä»¶']}")
        
        if download_results['å¤±è´¥'] > 0:
            print(f"\nâŒ å¤±è´¥çš„è§†é¢‘:")
            for video in download_results['å¤±è´¥è§†é¢‘']:
                print(f"   - {video.get('æ ‡é¢˜', 'unknown')} ({video.get('è§†é¢‘ID', 'unknown')})")
        
        print(f"{'='*60}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¬ ç®€åŒ–ç‰ˆæ‰¹é‡YouTubeè¯„è®ºä¸‹è½½å·¥å…·")
    print("=" * 60)
    
    # åˆå§‹åŒ–ä¸‹è½½å™¨
    downloader = SimpleBatchDownloader("simple_batch_output")
    
    while True:
        print(f"\n{'='*60}")
        print("è¯·é€‰æ‹©æ“ä½œæ¨¡å¼:")
        print("1. æ‰‹åŠ¨è¾“å…¥è§†é¢‘URLæ‰¹é‡ä¸‹è½½")
        print("2. ä»æ–‡ä»¶è¯»å–URLæ‰¹é‡ä¸‹è½½")
        print("3. å•ä¸ªè§†é¢‘URLä¸‹è½½")
        print("4. é€€å‡º")
        print("=" * 60)
        
        choice = input("è¯·è¾“å…¥é€‰æ‹© (1-4): ").strip()
        
        if choice == '1':
            # æ‰‹åŠ¨è¾“å…¥URL
            print("\nè¯·è¾“å…¥YouTubeè§†é¢‘URL (æ¯è¡Œä¸€ä¸ªï¼Œè¾“å…¥ç©ºè¡Œç»“æŸ):")
            urls = []
            while True:
                url = input().strip()
                if not url:
                    break
                if 'youtube.com' in url or 'youtu.be' in url:
                    urls.append(url)
                else:
                    print("âš ï¸ è¯·è¾“å…¥æœ‰æ•ˆçš„YouTube URL")
            
            if not urls:
                print("âŒ è‡³å°‘éœ€è¦ä¸€ä¸ªURL")
                continue
                
            # è½¬æ¢ä¸ºè§†é¢‘ä¿¡æ¯åˆ—è¡¨
            video_list = []
            for i, url in enumerate(urls):
                video_info = downloader.extract_video_info_from_url(url, i + 1)
                video_list.append(video_info)
            
            print(f"âœ… å…±è¾“å…¥ {len(video_list)} ä¸ªè§†é¢‘URL")
            
            # ä¿å­˜è§†é¢‘åˆ—è¡¨
            downloader.save_video_list_to_file(video_list)
            
        elif choice == '2':
            # ä»æ–‡ä»¶è¯»å–
            filepath = input("è¯·è¾“å…¥æ–‡ä»¶è·¯å¾„ (.json/.csv/.txt): ").strip()
            
            try:
                video_list = downloader.load_video_list_from_file(filepath)
                print(f"âœ… ä»æ–‡ä»¶ä¸­è¯»å–åˆ° {len(video_list)} ä¸ªè§†é¢‘")
            except Exception as e:
                print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
                continue
                
        elif choice == '3':
            # å•ä¸ªè§†é¢‘
            url = input("è¯·è¾“å…¥YouTubeè§†é¢‘URL: ").strip()
            if not url or 'youtube.com' not in url and 'youtu.be' not in url:
                print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„YouTube URL")
                continue
                
            video_info = downloader.extract_video_info_from_url(url)
            video_list = [video_info]
            
        elif choice == '4':
            print("ğŸ‘‹ å†è§!")
            break
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡è¯•")
            continue
        
        if choice in ['1', '2', '3']:
            # è¯„è®ºä¸‹è½½å‚æ•°è®¾ç½®
            print(f"\nâš™ï¸ è®¾ç½®ä¸‹è½½å‚æ•°:")
            
            try:
                limit = int(input("æ¯ä¸ªè§†é¢‘è¯„è®ºæ•°é‡é™åˆ¶ (é»˜è®¤100): ").strip() or "100")
            except:
                limit = 100
            
            sort_choice = input("æ’åºæ–¹å¼ (0=çƒ­é—¨, 1=æœ€æ–°, é»˜è®¤1): ").strip() or "1"
            sort = int(sort_choice) if sort_choice in ['0', '1'] else 1
            
            language = input("è¯­è¨€è®¾ç½® (å¦‚: zh, en, é»˜è®¤è‡ªåŠ¨): ").strip() or None
            
            pretty_choice = input("æ ¼å¼åŒ–JSONè¾“å‡º (y/n, é»˜è®¤y): ").strip().lower()
            pretty = pretty_choice != 'n'
            
            try:
                delay = int(input("ä¸‹è½½é—´éš”ç§’æ•° (é»˜è®¤2): ").strip() or "2")
            except:
                delay = 2
            
            # æ‰¹é‡ä¸‹è½½è¯„è®º
            download_results = downloader.batch_download_comments(
                video_list, limit, sort, language, pretty, delay
            )
            
            # ç”ŸæˆæŠ¥å‘Š
            downloader.generate_report(download_results)


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸ ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºå‡ºç°é”™è¯¯: {e}") 